{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:06.040583Z",
     "iopub.status.busy": "2023-07-31T06:11:06.040283Z",
     "iopub.status.idle": "2023-07-31T06:11:08.236735Z",
     "shell.execute_reply": "2023-07-31T06:11:08.235796Z",
     "shell.execute_reply.started": "2023-07-31T06:11:06.040560Z"
    },
    "ExecuteTime": {
     "end_time": "2023-10-08T21:43:46.585720Z",
     "start_time": "2023-10-08T21:43:45.352480Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "import os\n",
    "\n",
    "from taogpt.orchestrator import *\n",
    "from taogpt.utils import *\n",
    "from taogpt.llm_model import LangChainLLM\n",
    "from taogpt.prompts import PromptDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T21:43:47.918895Z",
     "start_time": "2023-10-08T21:43:47.898302Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:08.238613Z",
     "iopub.status.busy": "2023-07-31T06:11:08.238227Z",
     "iopub.status.idle": "2023-07-31T06:11:08.268068Z",
     "shell.execute_reply": "2023-07-31T06:11:08.267171Z",
     "shell.execute_reply.started": "2023-07-31T06:11:08.238592Z"
    },
    "ExecuteTime": {
     "end_time": "2023-10-08T21:43:49.024269Z",
     "start_time": "2023-10-08T21:43:49.004550Z"
    }
   },
   "outputs": [],
   "source": [
    "TEMPERATURE = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:08.269654Z",
     "iopub.status.busy": "2023-07-31T06:11:08.269017Z",
     "iopub.status.idle": "2023-07-31T06:11:10.109116Z",
     "shell.execute_reply": "2023-07-31T06:11:10.108307Z",
     "shell.execute_reply.started": "2023-07-31T06:11:08.269630Z"
    },
    "ExecuteTime": {
     "end_time": "2023-10-08T21:47:30.936452Z",
     "start_time": "2023-10-08T21:47:29.447229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"I am using OpenAI's GPT-3 model, which is the third iteration of the Generative Pre-trained Transformer model. It was released in June 2020 and has been trained on a vast amount of text data to generate human-like responses. GPT-3 has 175 billion parameters, making it one of the largest language models ever created.\""
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(os.environ['HOME'], '.ssh', 'openai-zillow.json'), 'r') as f:\n",
    "    credentials = json.load(f)\n",
    "os.environ[\"OPENAI_API_KEY\"] = credentials['key']\n",
    "os.environ[\"OPENAI_API_BASE\"] = credentials['url']\n",
    "llm3_5 = ChatOpenAI(model_name='gpt-3.5-turbo-16k', temperature=TEMPERATURE)\n",
    "llm4 = ChatOpenAI(model_name='gpt-4', temperature=TEMPERATURE)\n",
    "llm4_32k = ChatOpenAI(model_name='gpt-4-32k', temperature=TEMPERATURE)\n",
    "\n",
    "conversation = ConversationChain(llm=llm3_5)\n",
    "conversation.predict(input=\"What's your model version?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "('gpt-3.5-turbo-16k', 'gpt-4', 'gpt-4-32k')"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm3_5.model_name, llm4.model_name, llm4_32k.model_name"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T21:47:32.811674Z",
     "start_time": "2023-10-08T21:47:32.738347Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:10.111826Z",
     "iopub.status.busy": "2023-07-31T06:11:10.111407Z",
     "iopub.status.idle": "2023-07-31T06:12:26.695021Z",
     "shell.execute_reply": "2023-07-31T06:12:26.694244Z",
     "shell.execute_reply.started": "2023-07-31T06:11:10.111799Z"
    },
    "ExecuteTime": {
     "end_time": "2023-10-08T22:25:35.489046Z",
     "start_time": "2023-10-08T22:25:28.107905Z"
    }
   },
   "outputs": [
    {
     "ename": "Pause",
     "evalue": "Pause after initial solving expansion",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mPause\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 22\u001B[0m\n\u001B[1;32m     13\u001B[0m executor \u001B[38;5;241m=\u001B[39m Orchestrator(\n\u001B[1;32m     14\u001B[0m     config\u001B[38;5;241m=\u001B[39mconfig,\n\u001B[1;32m     15\u001B[0m     llm\u001B[38;5;241m=\u001B[39mLangChainLLM(llm3_5, logger\u001B[38;5;241m=\u001B[39mlogger),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     18\u001B[0m     sage_llm\u001B[38;5;241m=\u001B[39mLangChainLLM(llm4, logger\u001B[38;5;241m=\u001B[39mlogger),\n\u001B[1;32m     19\u001B[0m )\n\u001B[1;32m     21\u001B[0m experiment_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexample\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m---> 22\u001B[0m \u001B[43mexecutor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\"\"\u001B[39;49m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;124;43mWhat\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43ms x mod (y - z) where x = 10, y = 7, z = 4.\u001B[39;49m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;124;43m\"\"\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# executor.start(\"\"\"\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# Solve this 4x4 Sudoku.\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# Solve in your head. Do NOT use Python programming.\u001B[39;00m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;66;03m# \"\"\", analyze_first=True)\u001B[39;00m\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/orchestrator.py:84\u001B[0m, in \u001B[0;36mOrchestrator.start\u001B[0;34m(self, task)\u001B[0m\n\u001B[1;32m     82\u001B[0m     init_analysis_step \u001B[38;5;241m=\u001B[39m AnalysisStep(root_step, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, ROLE_ORCHESTRATOR)\n\u001B[1;32m     83\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chain\u001B[38;5;241m.\u001B[39mappend(init_analysis_step)\n\u001B[0;32m---> 84\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_with_backtracking\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/orchestrator.py:119\u001B[0m, in \u001B[0;36mOrchestrator._execute_with_backtracking\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chain) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    118\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 119\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    120\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m Backtrack \u001B[38;5;28;01mas\u001B[39;00m backtrack:\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/orchestrator.py:163\u001B[0m, in \u001B[0;36mOrchestrator._loop\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_loop\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 163\u001B[0m         new_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_chain\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    164\u001B[0m         \u001B[38;5;28;01mwhile\u001B[39;00m new_step \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    165\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chain\u001B[38;5;241m.\u001B[39mappend(new_step) \u001B[38;5;66;03m# note: we don't necessary eval the new resulting step\u001B[39;00m\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/program.py:53\u001B[0m, in \u001B[0;36mStep.eval\u001B[0;34m(self, executor)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21meval\u001B[39m(\u001B[38;5;28mself\u001B[39m, executor: Executor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Step \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 53\u001B[0m     returned \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval_only\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexecutor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m returned\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/program.py:528\u001B[0m, in \u001B[0;36mExpandableStep.eval_only\u001B[0;34m(self, executor)\u001B[0m\n\u001B[1;32m    526\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrank_choices(executor, n_existing_choices\u001B[38;5;241m=\u001B[39mold_length)\n\u001B[1;32m    527\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfirst_problem_solving_step \u001B[38;5;129;01mand\u001B[39;00m executor\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mpause_after_initial_solving_expansion:\n\u001B[0;32m--> 528\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Pause(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPause after initial solving expansion\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    529\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchoices \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchoices) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    530\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Backtrack(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNo viable options.\u001B[39m\u001B[38;5;124m'\u001B[39m, blame\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[0;31mPause\u001B[0m: Pause after initial solving expansion"
     ]
    }
   ],
   "source": [
    "prompts = PromptDb.load_defaults()\n",
    "logger = MarkdownLogger('logs/taogpt_log.md')\n",
    "config = Config(\n",
    "    ask_user_before_execute_codes=False,\n",
    "    ask_user_questions_in_one_prompt=True,\n",
    "    pause_after_initial_solving_expansion=True,\n",
    "    first_expansion=1,\n",
    "    initial_expansion=2,\n",
    "    max_tree_branches=6,\n",
    "    max_tokens=5000,\n",
    "    check_final=True\n",
    ")\n",
    "executor = Orchestrator(\n",
    "    config=config,\n",
    "    llm=LangChainLLM(llm3_5, logger=logger),\n",
    "    prompts=prompts,\n",
    "    markdown_logger=logger,\n",
    "    sage_llm=LangChainLLM(llm4, logger=logger),\n",
    ")\n",
    "\n",
    "experiment_name = 'example'\n",
    "executor.start(\"\"\"\n",
    "What's x mod (y - z) where x = 10, y = 7, z = 4.\n",
    "\"\"\")\n",
    "# executor.start(\"\"\"\n",
    "# Solve this 4x4 Sudoku.\n",
    "#\n",
    "# ```text\n",
    "# _ 3 _ 1\n",
    "# 1 _ _ 3\n",
    "# 2 _ 3 _\n",
    "# 3 4 _ 2\n",
    "# ```\n",
    "#\n",
    "# (`_` represents an empty cell.)\n",
    "#\n",
    "# Solve in your head. Do NOT use Python programming.\n",
    "# \"\"\", analyze_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# executor._chain[11].step.description"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T22:02:01.233352Z",
     "start_time": "2023-10-08T22:02:01.198139Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# executor._chain = executor._chain[:11]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T22:02:07.063255Z",
     "start_time": "2023-10-08T22:02:07.029091Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# executor.chain[-1].step.description"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T22:02:12.046943Z",
     "start_time": "2023-10-08T22:02:12.020125Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# executor._prompts = PromptDb.load_defaults()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T22:02:15.715604Z",
     "start_time": "2023-10-08T22:02:15.681703Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "executor.resume(5000, additional_tokens_for_smarter_llm=0, unblock_initial_expansion=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T22:26:03.643062Z",
     "start_time": "2023-10-08T22:26:02.870761Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:12:26.696369Z",
     "iopub.status.busy": "2023-07-31T06:12:26.696162Z",
     "iopub.status.idle": "2023-07-31T06:12:26.726978Z",
     "shell.execute_reply": "2023-07-31T06:12:26.726366Z",
     "shell.execute_reply.started": "2023-07-31T06:12:26.696352Z"
    },
    "ExecuteTime": {
     "end_time": "2023-10-08T22:08:00.099747Z",
     "start_time": "2023-10-08T22:08:00.070197Z"
    }
   },
   "outputs": [],
   "source": [
    "logger = MarkdownLogger(f'examples/{experiment_name}.final.md')\n",
    "executor.log_configs(logger)\n",
    "logger.log_conversation(executor.show_conversation_thread(with_header=True))\n",
    "logger.log(f\"**total tokens**: {executor.llm.total_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:06.040583Z",
     "iopub.status.busy": "2023-07-31T06:11:06.040283Z",
     "iopub.status.idle": "2023-07-31T06:11:08.236735Z",
     "shell.execute_reply": "2023-07-31T06:11:08.235796Z",
     "shell.execute_reply.started": "2023-07-31T06:11:06.040560Z"
    },
    "ExecuteTime": {
     "end_time": "2023-09-27T04:25:01.767591Z",
     "start_time": "2023-09-27T04:25:00.437755Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "import os\n",
    "from IPython.display import display_html\n",
    "import marko\n",
    "\n",
    "from taogpt.orchestrator import *\n",
    "from taogpt.utils import *\n",
    "from taogpt.llm_model import LangChainLLM\n",
    "from taogpt.prompts import PromptDb\n",
    "import taogpt.utils as utils\n",
    "\n",
    "utils.enable_debugging(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T04:25:02.863904Z",
     "start_time": "2023-09-27T04:25:02.841317Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:08.238613Z",
     "iopub.status.busy": "2023-07-31T06:11:08.238227Z",
     "iopub.status.idle": "2023-07-31T06:11:08.268068Z",
     "shell.execute_reply": "2023-07-31T06:11:08.267171Z",
     "shell.execute_reply.started": "2023-07-31T06:11:08.238592Z"
    },
    "ExecuteTime": {
     "end_time": "2023-09-27T04:25:04.418298Z",
     "start_time": "2023-09-27T04:25:04.402139Z"
    }
   },
   "outputs": [],
   "source": [
    "TEMPERATURE = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:08.269654Z",
     "iopub.status.busy": "2023-07-31T06:11:08.269017Z",
     "iopub.status.idle": "2023-07-31T06:11:10.109116Z",
     "shell.execute_reply": "2023-07-31T06:11:10.108307Z",
     "shell.execute_reply.started": "2023-07-31T06:11:08.269630Z"
    },
    "ExecuteTime": {
     "end_time": "2023-09-27T04:25:09.018410Z",
     "start_time": "2023-09-27T04:25:08.181551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'I am an OpenAI GPT-3 model, which is the third iteration of the Generative Pre-trained Transformer model developed by OpenAI.'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(os.environ['HOME'], '.ssh', 'openai-zillow.json'), 'r') as f:\n",
    "    credentials = json.load(f)\n",
    "os.environ[\"OPENAI_API_KEY\"] = credentials['key']\n",
    "os.environ[\"OPENAI_API_BASE\"] = credentials['url']\n",
    "llm3_5 = ChatOpenAI(model_name='gpt-3.5-turbo-16k', temperature=TEMPERATURE)\n",
    "llm4 = ChatOpenAI(model_name='gpt-4-32k', temperature=TEMPERATURE)\n",
    "\n",
    "conversation = ConversationChain(llm=llm3_5)\n",
    "conversation.predict(input=\"What's your model version?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "('gpt-3.5-turbo-16k', 'gpt-4-32k')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm3_5.model_name, llm4.model_name"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T04:25:13.900551Z",
     "start_time": "2023-09-27T04:25:13.866562Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:10.111826Z",
     "iopub.status.busy": "2023-07-31T06:11:10.111407Z",
     "iopub.status.idle": "2023-07-31T06:12:26.695021Z",
     "shell.execute_reply": "2023-07-31T06:12:26.694244Z",
     "shell.execute_reply.started": "2023-07-31T06:11:10.111799Z"
    },
    "ExecuteTime": {
     "end_time": "2023-09-28T04:39:19.094443Z",
     "start_time": "2023-09-28T04:38:55.877239Z"
    }
   },
   "outputs": [],
   "source": [
    "prompts = PromptDb.load_defaults()\n",
    "logger = MarkdownLogger('logs/taogpt_log.md')\n",
    "executor = Orchestrator(llm=LangChainLLM(llm4, logger=logger), prompts=prompts, markdown_logger=logger,\n",
    "                        initial_expansion=1,\n",
    "                        max_tree_branches=2,\n",
    "                        max_tokens=10000,\n",
    "                        check_final=True,\n",
    "                        # smarter_llm=LangChainLLM(llm4, logger=logger),\n",
    "                        )\n",
    "\n",
    "experiment_name = 'example'\n",
    "executor.start(\"\"\"\n",
    "Solve this Game of 24: 7, 6, 2, 1\n",
    "\"\"\", analyze_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extend token allowance by 10000 to 20000\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Regular LLM consumed 22718 tokens, exceeded allowance of 20000",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mexecutor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresume\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m10000\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/orchestrator.py:101\u001B[0m, in \u001B[0;36mOrchestrator.resume\u001B[0;34m(self, additional_tokens, additional_tokens_for_smarter_llm)\u001B[0m\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_max_tokens_for_sage_llm \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m additional_tokens_for_smarter_llm\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mextend token allowance for smarter LLM by \u001B[39m\u001B[38;5;132;01m{\u001B[39;00madditional_tokens_for_smarter_llm\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    100\u001B[0m           \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_max_tokens_for_sage_llm\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 101\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_with_backtracking\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/orchestrator.py:107\u001B[0m, in \u001B[0;36mOrchestrator._execute_with_backtracking\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chain) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    106\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 107\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    108\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_frozen_chain \u001B[38;5;241m=\u001B[39m _FrozenList(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chain)\n\u001B[1;32m    109\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/orchestrator.py:168\u001B[0m, in \u001B[0;36mOrchestrator._loop\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    166\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msummarize_final_answer()\n\u001B[1;32m    167\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m--> 168\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_token_usages\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    169\u001B[0m     new_step \u001B[38;5;241m=\u001B[39m new_step\u001B[38;5;241m.\u001B[39meval(new_invocation)\n\u001B[1;32m    170\u001B[0m new_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnext_step()\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/orchestrator.py:182\u001B[0m, in \u001B[0;36mOrchestrator.check_token_usages\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcheck_token_usages\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    181\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;241m0\u001B[39m \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_max_tokens \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm\u001B[38;5;241m.\u001B[39mtotal_tokens:\n\u001B[0;32m--> 182\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRegular LLM consumed \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm\u001B[38;5;241m.\u001B[39mtotal_tokens\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m tokens, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    183\u001B[0m                            \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexceeded allowance of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_max_tokens\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mid\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mid\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msage_llm) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;241m0\u001B[39m \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_max_tokens_for_sage_llm \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msage_llm\u001B[38;5;241m.\u001B[39mtotal_tokens:\n\u001B[1;32m    185\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSmarter LLM consumed \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msage_llm\u001B[38;5;241m.\u001B[39mtotal_tokens\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m tokens, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    186\u001B[0m                            \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexceeded allowance of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_max_tokens_for_sage_llm\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Regular LLM consumed 22718 tokens, exceeded allowance of 20000"
     ]
    }
   ],
   "source": [
    "executor.resume(10000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:12:26.696369Z",
     "iopub.status.busy": "2023-07-31T06:12:26.696162Z",
     "iopub.status.idle": "2023-07-31T06:12:26.726978Z",
     "shell.execute_reply": "2023-07-31T06:12:26.726366Z",
     "shell.execute_reply.started": "2023-07-31T06:12:26.696352Z"
    },
    "ExecuteTime": {
     "end_time": "2023-09-28T04:41:40.401892Z",
     "start_time": "2023-09-28T04:41:40.336532Z"
    }
   },
   "outputs": [],
   "source": [
    "logger = MarkdownLogger(f'examples/{experiment_name}.final.md')\n",
    "logger.log_conversation(executor.show_conversation_thread(with_extras=True))\n",
    "logger.log(f\"**total tokens**: {executor.llm.total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:12:26.728306Z",
     "iopub.status.busy": "2023-07-31T06:12:26.728050Z",
     "iopub.status.idle": "2023-07-31T06:12:26.762760Z",
     "shell.execute_reply": "2023-07-31T06:12:26.762149Z",
     "shell.execute_reply.started": "2023-07-31T06:12:26.728288Z"
    },
    "ExecuteTime": {
     "end_time": "2023-09-28T04:41:41.190312Z",
     "start_time": "2023-09-28T04:41:41.158843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div style=\"background-color: beige; text-align: center; padding: 5px\">\n<h1>Final path history</h1>\n</div>\n<div style=\"background-color:lightgreen; display: flex; border-bottom: 1px dotted grey\">\n<div style=\"flex: 130px\">\n<p>[0] <strong>user</strong></p>\n</div>\n<div style=\"flex: 100%; border-left: 1px dotted grey; padding-left: 5px\">\n<p>Solve this Game of 24: 7, 6, 2, 1</p>\n</div>\n</div>\n<div style=\"background-color:lightcyan; display: flex; border-bottom: 1px dotted grey\">\n<div style=\"flex: 130px\">\n<p>[1] <strong>orchestrator</strong></p>\n</div>\n<div style=\"flex: 100%; border-left: 1px dotted grey; padding-left: 5px\">\n<p>Some critics said this problem is not solvable due to fundamental errors. Other critics said it is solvable.</p>\n<p>Does the task problem contain any fundamental errors, invalid assumptions, or contradiction in the problem statement?</p>\n<p>Do not try to solve the problem yet, just provide analysis.</p>\n</div>\n</div>\n<div style=\"background-color:lightyellow; display: flex; border-bottom: 1px dotted grey\">\n<div style=\"flex: 130px\">\n<p>[2] <strong>Tao</strong></p>\n</div>\n<div style=\"flex: 100%; border-left: 1px dotted grey; padding-left: 5px\">\n<p>The problem statement is clear and does not contain any fundamental errors, invalid assumptions, or contradictions. The task is to use the four given numbers (7, 6, 2, 1) in any combination of addition, subtraction, multiplication, and division to arrive at the number 24. Each number must be used exactly once and the order of operations should be considered. This is a standard format for a Game of 24 problem.</p>\n</div>\n</div>\n<div style=\"background-color:lightcyan; display: flex; border-bottom: 1px dotted grey\">\n<div style=\"flex: 130px\">\n<p>[3] <strong>orchestrator</strong></p>\n</div>\n<div style=\"flex: 100%; border-left: 1px dotted grey; padding-left: 5px\">\n<p>Tao, please proceed. You <strong>must follow the response templates strictly</strong> so that your orchestrator\ncan parse your response. Think carefully before responding.</p>\n</div>\n</div>\n<div style=\"background-color:lightyellow; display: flex; border-bottom: 1px dotted grey\">\n<div style=\"flex: 130px\">\n<p>[4] <strong>Tao</strong></p>\n</div>\n<div style=\"flex: 100%; border-left: 1px dotted grey; padding-left: 5px\">\n<p>The task requires us to use the four given numbers (7, 6, 2, 1) in any combination of addition, subtraction, multiplication, and division to arrive at the number 24. Each number must be used exactly once and the order of operations should be considered.</p>\n<ol>\n<li>Try different combinations of the four numbers using the four operations. [This step is necessary because the solution could be any combination of the four numbers with the four operations.]</li>\n<li>Evaluate each combination to see if it equals 24. [This step is necessary to check if the combination is a valid solution to the problem.]</li>\n<li>If a combination equals 24, then that is the solution. If no combination equals 24, then the problem is unsolvable with the given numbers. [This step is necessary to determine the solution or conclude that there is no solution.]</li>\n</ol>\n</div>\n</div>\n<div style=\"background-color:lightcyan; display: flex; border-bottom: 1px dotted grey\">\n<div style=\"flex: 130px\">\n<p>[5] <strong>orchestrator</strong></p>\n</div>\n<div style=\"flex: 100%; border-left: 1px dotted grey; padding-left: 5px\">\n<p>Tao, please proceed to work on the first step of the above plan. You <strong>must follow the response templates strictly</strong>\nso that your orchestrator can parse your response. Think carefully before responding.</p>\n</div>\n</div>\n<div style=\"background-color:lightyellow; display: flex; border-bottom: 1px dotted grey\">\n<div style=\"flex: 130px\">\n<p>[6] <strong>Tao</strong></p>\n</div>\n<div style=\"flex: 100%; border-left: 1px dotted grey; padding-left: 5px\">\n<p>After trying different combinations of the four numbers using the four operations, I found that the following combination results in 24:</p>\n<ol>\n<li>Multiply 6 and 2 to get 12.</li>\n<li>Subtract 1 from 7 to get 6.</li>\n<li>Multiply the results from steps 1 and 2 to get 24.</li>\n</ol>\n<p>So, the solution is (6 * 2) * (7 - 1) = 24.</p>\n</div>\n</div>\n<div style=\"background-color:lightyellow; display: flex; border-bottom: 1px dotted grey\">\n<div style=\"flex: 130px\">\n<p>[7] <strong>Tao</strong></p>\n</div>\n<div style=\"flex: 100%; border-left: 1px dotted grey; padding-left: 5px\">\n<p>The solution to the Game of 24 problem with the numbers 7, 6, 2, 1 is to multiply 6 and 2 to get 12, subtract 1 from 7 to get 6, and then multiply these two results to get 24. So, the solution is (6 * 2) * (7 - 1) = 24.</p>\n</div>\n</div>\n<p><strong>total tokens</strong>: 3683</p>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(logger._log_path, 'r') as f:\n",
    "    html_output = marko.convert(f.read())\n",
    "    display_html(html_output, raw=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

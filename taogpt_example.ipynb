{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:06.040583Z",
     "iopub.status.busy": "2023-07-31T06:11:06.040283Z",
     "iopub.status.idle": "2023-07-31T06:11:08.236735Z",
     "shell.execute_reply": "2023-07-31T06:11:08.235796Z",
     "shell.execute_reply.started": "2023-07-31T06:11:06.040560Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "import os\n",
    "\n",
    "from taogpt.orchestrator import *\n",
    "from taogpt.utils import *\n",
    "from taogpt.llm_model import LangChainLLM\n",
    "from taogpt.prompts import PromptDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:08.238613Z",
     "iopub.status.busy": "2023-07-31T06:11:08.238227Z",
     "iopub.status.idle": "2023-07-31T06:11:08.268068Z",
     "shell.execute_reply": "2023-07-31T06:11:08.267171Z",
     "shell.execute_reply.started": "2023-07-31T06:11:08.238592Z"
    }
   },
   "outputs": [],
   "source": [
    "TEMPERATURE = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:08.269654Z",
     "iopub.status.busy": "2023-07-31T06:11:08.269017Z",
     "iopub.status.idle": "2023-07-31T06:11:10.109116Z",
     "shell.execute_reply": "2023-07-31T06:11:10.108307Z",
     "shell.execute_reply.started": "2023-07-31T06:11:08.269630Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(os.environ['HOME'], '.ssh', 'openai-zillow.json'), 'r') as f:\n",
    "    credentials = json.load(f)\n",
    "os.environ[\"OPENAI_API_KEY\"] = credentials['key']\n",
    "os.environ[\"OPENAI_API_BASE\"] = credentials['url']\n",
    "llm3_5 = ChatOpenAI(model_name='gpt-3.5-turbo-16k', temperature=TEMPERATURE)\n",
    "llm4 = ChatOpenAI(model_name='gpt-4', temperature=TEMPERATURE)\n",
    "llm4_32k = ChatOpenAI(model_name='gpt-4-32k', temperature=TEMPERATURE)\n",
    "\n",
    "conversation = ConversationChain(llm=llm3_5)\n",
    "conversation.predict(input=\"What's your model version?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm3_5.model_name, llm4.model_name, llm4_32k.model_name"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:10.111826Z",
     "iopub.status.busy": "2023-07-31T06:11:10.111407Z",
     "iopub.status.idle": "2023-07-31T06:12:26.695021Z",
     "shell.execute_reply": "2023-07-31T06:12:26.694244Z",
     "shell.execute_reply.started": "2023-07-31T06:11:10.111799Z"
    }
   },
   "outputs": [],
   "source": [
    "prompts = PromptDb.load_defaults()\n",
    "logger = MarkdownLogger('logs/taogpt_log.md')\n",
    "config = Config(\n",
    "    ask_user_before_execute_codes=False,\n",
    "    ask_user_questions_in_one_prompt=True,\n",
    "    pause_after_initial_solving_expansion=True,\n",
    "    first_expansion=1,\n",
    "    initial_expansion=3,\n",
    "    max_search_expansion=2,\n",
    "    first_try_temperature=0.,\n",
    "    max_tokens=10000,\n",
    "    check_final=True\n",
    ")\n",
    "\n",
    "primary_model = 4\n",
    "sage_model = None\n",
    "\n",
    "if primary_model == 4:\n",
    "    primary_model = LangChainLLM(llm4, logger=logger, long_context_llm=llm4_32k, long_context_token_threshold=3000)\n",
    "    _ = sage_model\n",
    "    sage_model = primary_model\n",
    "else:\n",
    "    primary_model = LangChainLLM(llm3_5, logger=logger)\n",
    "    sage_model = LangChainLLM(llm4, logger=logger, long_context_llm=llm4_32k, long_context_token_threshold=3000) \\\n",
    "        if sage_model is None or sage_model == 4 else primary_model\n",
    "\n",
    "executor = Orchestrator(\n",
    "    config=config,\n",
    "    llm=primary_model,\n",
    "    prompts=prompts,\n",
    "    markdown_logger=logger,\n",
    "    sage_llm=sage_model,\n",
    ")\n",
    "\n",
    "experiment_name = 'example'\n",
    "# executor.start(\"\"\"What's x mod (y - z) where x = 10, y = 7, z = 4.\"\"\")\n",
    "executor.start(\"\"\"\n",
    "Tao, find a quote from Tao Te Ching which best describe your problem solving philosophy, especially the recursively\n",
    "generating tree-structure for any problems given to you, starting with a single set of principles and rules.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "backup_chain = executor.chain.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "executor._prompts = PromptDb.load_defaults()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# executor._chain = executor._chain[:-1]\n",
    "executor._chain[-1].description"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "executor.resume(10000, additional_tokens_for_smarter_llm=500, unblock_initial_expansion=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:12:26.696369Z",
     "iopub.status.busy": "2023-07-31T06:12:26.696162Z",
     "iopub.status.idle": "2023-07-31T06:12:26.726978Z",
     "shell.execute_reply": "2023-07-31T06:12:26.726366Z",
     "shell.execute_reply.started": "2023-07-31T06:12:26.696352Z"
    }
   },
   "outputs": [],
   "source": [
    "logger = MarkdownLogger(f'examples/{experiment_name}.final.md')\n",
    "executor.log_configs(logger)\n",
    "logger.log_conversation(executor.show_conversation_thread(with_header=True))\n",
    "logger.log(f\"**total tokens**: {executor.llm.total_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

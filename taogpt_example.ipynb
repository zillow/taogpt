{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:06.040583Z",
     "iopub.status.busy": "2023-07-31T06:11:06.040283Z",
     "iopub.status.idle": "2023-07-31T06:11:08.236735Z",
     "shell.execute_reply": "2023-07-31T06:11:08.235796Z",
     "shell.execute_reply.started": "2023-07-31T06:11:06.040560Z"
    },
    "ExecuteTime": {
     "end_time": "2023-10-07T00:10:02.573928Z",
     "start_time": "2023-10-07T00:10:01.267064Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "import os\n",
    "\n",
    "from taogpt.orchestrator import *\n",
    "from taogpt.utils import *\n",
    "from taogpt.llm_model import LangChainLLM\n",
    "from taogpt.prompts import PromptDb\n",
    "import taogpt.utils as utils\n",
    "\n",
    "utils.enable_debugging(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T00:10:02.594159Z",
     "start_time": "2023-10-07T00:10:02.556862Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:08.238613Z",
     "iopub.status.busy": "2023-07-31T06:11:08.238227Z",
     "iopub.status.idle": "2023-07-31T06:11:08.268068Z",
     "shell.execute_reply": "2023-07-31T06:11:08.267171Z",
     "shell.execute_reply.started": "2023-07-31T06:11:08.238592Z"
    },
    "ExecuteTime": {
     "end_time": "2023-10-07T00:10:02.791046Z",
     "start_time": "2023-10-07T00:10:02.770546Z"
    }
   },
   "outputs": [],
   "source": [
    "TEMPERATURE = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:08.269654Z",
     "iopub.status.busy": "2023-07-31T06:11:08.269017Z",
     "iopub.status.idle": "2023-07-31T06:11:10.109116Z",
     "shell.execute_reply": "2023-07-31T06:11:10.108307Z",
     "shell.execute_reply.started": "2023-07-31T06:11:08.269630Z"
    },
    "ExecuteTime": {
     "end_time": "2023-10-07T00:10:04.020249Z",
     "start_time": "2023-10-07T00:10:03.296284Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"I am using OpenAI's GPT-3 model.\""
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(os.environ['HOME'], '.ssh', 'openai-zillow.json'), 'r') as f:\n",
    "    credentials = json.load(f)\n",
    "os.environ[\"OPENAI_API_KEY\"] = credentials['key']\n",
    "os.environ[\"OPENAI_API_BASE\"] = credentials['url']\n",
    "llm3_5 = ChatOpenAI(model_name='gpt-3.5-turbo-16k', temperature=TEMPERATURE)\n",
    "llm4 = ChatOpenAI(model_name='gpt-4-32k', temperature=TEMPERATURE)\n",
    "\n",
    "conversation = ConversationChain(llm=llm3_5)\n",
    "conversation.predict(input=\"What's your model version?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "('gpt-3.5-turbo-16k', 'gpt-4-32k')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm3_5.model_name, llm4.model_name"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T00:10:04.139950Z",
     "start_time": "2023-10-07T00:10:04.119954Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:10.111826Z",
     "iopub.status.busy": "2023-07-31T06:11:10.111407Z",
     "iopub.status.idle": "2023-07-31T06:12:26.695021Z",
     "shell.execute_reply": "2023-07-31T06:12:26.694244Z",
     "shell.execute_reply.started": "2023-07-31T06:11:10.111799Z"
    },
    "ExecuteTime": {
     "end_time": "2023-10-07T00:22:02.663321Z",
     "start_time": "2023-10-07T00:21:32.428848Z"
    }
   },
   "outputs": [
    {
     "ename": "Pause",
     "evalue": "Pause after initial solving expansion",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mPause\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 22\u001B[0m\n\u001B[1;32m     13\u001B[0m executor \u001B[38;5;241m=\u001B[39m Orchestrator(\n\u001B[1;32m     14\u001B[0m     config\u001B[38;5;241m=\u001B[39mconfig,\n\u001B[1;32m     15\u001B[0m     llm\u001B[38;5;241m=\u001B[39mLangChainLLM(llm4, logger\u001B[38;5;241m=\u001B[39mlogger),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;66;03m# sage_llm=LangChainLLM(llm4, logger=logger),\u001B[39;00m\n\u001B[1;32m     19\u001B[0m )\n\u001B[1;32m     21\u001B[0m experiment_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexample\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m---> 22\u001B[0m \u001B[43mexecutor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\"\"\u001B[39;49m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;124;43mSolve this 4x4 Sudoku.\u001B[39;49m\n\u001B[1;32m     24\u001B[0m \n\u001B[1;32m     25\u001B[0m \u001B[38;5;124;43m```text\u001B[39;49m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;124;43m_ 3 _ 1\u001B[39;49m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;124;43m1 _ _ 3\u001B[39;49m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;124;43m2 _ 3 _\u001B[39;49m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;124;43m3 4 _ 2\u001B[39;49m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;124;43m```\u001B[39;49m\n\u001B[1;32m     31\u001B[0m \n\u001B[1;32m     32\u001B[0m \u001B[38;5;124;43m(`_` represents an empty cell.)\u001B[39;49m\n\u001B[1;32m     33\u001B[0m \n\u001B[1;32m     34\u001B[0m \u001B[38;5;124;43mSolve in your head. Do NOT use Python programming.\u001B[39;49m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;124;43m\"\"\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43manalyze_first\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/orchestrator.py:84\u001B[0m, in \u001B[0;36mOrchestrator.start\u001B[0;34m(self, task, analyze_first)\u001B[0m\n\u001B[1;32m     82\u001B[0m     init_analysis_step \u001B[38;5;241m=\u001B[39m AnalysisStep(root_step, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, ROLE_ORCHESTRATOR)\n\u001B[1;32m     83\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chain\u001B[38;5;241m.\u001B[39mappend(Invocation(init_analysis_step, _executor\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m))\n\u001B[0;32m---> 84\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_with_backtracking\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/orchestrator.py:104\u001B[0m, in \u001B[0;36mOrchestrator._execute_with_backtracking\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chain) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    103\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 104\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    105\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_frozen_chain \u001B[38;5;241m=\u001B[39m _FrozenList(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chain)\n\u001B[1;32m    106\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/orchestrator.py:157\u001B[0m, in \u001B[0;36mOrchestrator._loop\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    155\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    156\u001B[0m     invocation \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chain[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m--> 157\u001B[0m     new_step \u001B[38;5;241m=\u001B[39m \u001B[43minvocation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval\u001B[49m\u001B[43m(\u001B[49m\u001B[43minvocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    158\u001B[0m     invocation\u001B[38;5;241m.\u001B[39mexecution_count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    159\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m new_step \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/program.py:71\u001B[0m, in \u001B[0;36mStep.eval\u001B[0;34m(self, my_invocation)\u001B[0m\n\u001B[1;32m     69\u001B[0m sig \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msid\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m@\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mid\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m@\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mid\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mid\u001B[39m(my_invocation\u001B[38;5;241m.\u001B[39mstep)\n\u001B[0;32m---> 71\u001B[0m returned \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval_only\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmy_invocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m returned\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/program.py:553\u001B[0m, in \u001B[0;36mExpandableStep.eval_only\u001B[0;34m(self, my_invocation)\u001B[0m\n\u001B[1;32m    551\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrank_choices(my_invocation, n_existing_choices\u001B[38;5;241m=\u001B[39mold_length)\n\u001B[1;32m    552\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfirst_problem_solving_step \u001B[38;5;129;01mand\u001B[39;00m my_invocation\u001B[38;5;241m.\u001B[39mexecutor\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mpause_after_initial_solving_expansion:\n\u001B[0;32m--> 553\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Pause(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPause after initial solving expansion\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    554\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchoices \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchoices) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    555\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Backtrack(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNo viable options.\u001B[39m\u001B[38;5;124m'\u001B[39m, blame\u001B[38;5;241m=\u001B[39mmy_invocation)\n",
      "\u001B[0;31mPause\u001B[0m: Pause after initial solving expansion"
     ]
    }
   ],
   "source": [
    "prompts = PromptDb.load_defaults()\n",
    "logger = MarkdownLogger('logs/taogpt_log.md')\n",
    "config = Config(\n",
    "    ask_user_before_execute_codes=False,\n",
    "    ask_user_questions_in_one_prompt=True,\n",
    "    pause_after_initial_solving_expansion=True,\n",
    "    first_expansion=1,\n",
    "    initial_expansion=4,\n",
    "    max_tree_branches=6,\n",
    "    max_tokens=5000,\n",
    "    check_final=True\n",
    ")\n",
    "executor = Orchestrator(\n",
    "    config=config,\n",
    "    llm=LangChainLLM(llm4, logger=logger),\n",
    "    prompts=prompts,\n",
    "    markdown_logger=logger,\n",
    "    # sage_llm=LangChainLLM(llm4, logger=logger),\n",
    ")\n",
    "\n",
    "experiment_name = 'example'\n",
    "executor.start(\"\"\"\n",
    "Solve this 4x4 Sudoku.\n",
    "\n",
    "```text\n",
    "_ 3 _ 1\n",
    "1 _ _ 3\n",
    "2 _ 3 _\n",
    "3 4 _ 2\n",
    "```\n",
    "\n",
    "(`_` represents an empty cell.)\n",
    "\n",
    "Solve in your head. Do NOT use Python programming.\n",
    "\"\"\", analyze_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "'The fourth row of the Sudoku puzzle is `3 4 _ 2`. The missing numbers in this row are 1 and 4. \\n\\nSince the number 1 is already present in the second column (in the third row), the third cell of the fourth row cannot be 1. Therefore, it must be 4. \\n\\nSo, the fourth row after filling in the missing numbers is `3 4 1 2`.'"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executor._chain[11].step.description"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T00:37:50.693458Z",
     "start_time": "2023-10-07T00:37:50.670385Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "executor._chain = executor._chain[:11]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T00:38:14.487290Z",
     "start_time": "2023-10-07T00:38:14.467756Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "'Tao, some critic says your last step answer has errors while others think it\\'s OK. Please check the steps done so far.\\nIf there are indeed errors, respond using the `BACKTRACK_ON_ERROR` strategy, otherwise proceed to step \\n\\n* None. This is the final step.\\n\\nfollowing **strictly** the \"Problem Solving Instructions\" and templates above. Be sure to start with one of the \\nheadings: `# I_WILL_ANSWER_DIRECTLY`, `# LET_ME_ASK_THE_PYTHON_GENIE`, `# BACKTRACK_ON_ERROR`, \\n`# I_NEED_TO_ASK_SOME_QUESTIONS_BEFORE_I_PROCEED`, or `# HERE_IS_MY_STEP_BY_STEP_PLAN`.\\n\\n'"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executor.chain[-1].step.description"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T00:38:15.462130Z",
     "start_time": "2023-10-07T00:38:15.437220Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# executor._prompts = PromptDb.load_defaults()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T20:57:52.161211Z",
     "start_time": "2023-10-06T20:57:52.143036Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extend token allowance by 10000 to 55000\n",
      "extend token allowance for smarter LLM by 0 to 5000\n"
     ]
    }
   ],
   "source": [
    "executor.resume(10000, additional_tokens_for_smarter_llm=0, unblock_initial_expansion=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:12:26.696369Z",
     "iopub.status.busy": "2023-07-31T06:12:26.696162Z",
     "iopub.status.idle": "2023-07-31T06:12:26.726978Z",
     "shell.execute_reply": "2023-07-31T06:12:26.726366Z",
     "shell.execute_reply.started": "2023-07-31T06:12:26.696352Z"
    },
    "ExecuteTime": {
     "end_time": "2023-10-06T20:55:18.460251Z",
     "start_time": "2023-10-06T20:55:18.435738Z"
    }
   },
   "outputs": [],
   "source": [
    "logger = MarkdownLogger(f'examples/{experiment_name}.final.md')\n",
    "logger.log_conversation(executor.show_conversation_thread(with_header=True))\n",
    "logger.log(f\"**total tokens**: {executor.llm.total_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

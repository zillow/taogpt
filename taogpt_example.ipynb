{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:06.040583Z",
     "iopub.status.busy": "2023-07-31T06:11:06.040283Z",
     "iopub.status.idle": "2023-07-31T06:11:08.236735Z",
     "shell.execute_reply": "2023-07-31T06:11:08.235796Z",
     "shell.execute_reply.started": "2023-07-31T06:11:06.040560Z"
    },
    "ExecuteTime": {
     "end_time": "2023-09-29T16:30:56.299364Z",
     "start_time": "2023-09-29T16:30:55.079808Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "import os\n",
    "from IPython.display import display_html\n",
    "import marko\n",
    "\n",
    "from taogpt.orchestrator import *\n",
    "from taogpt.utils import *\n",
    "from taogpt.llm_model import LangChainLLM\n",
    "from taogpt.prompts import PromptDb\n",
    "import taogpt.utils as utils\n",
    "\n",
    "utils.enable_debugging(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T16:30:57.176751Z",
     "start_time": "2023-09-29T16:30:57.154336Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:08.238613Z",
     "iopub.status.busy": "2023-07-31T06:11:08.238227Z",
     "iopub.status.idle": "2023-07-31T06:11:08.268068Z",
     "shell.execute_reply": "2023-07-31T06:11:08.267171Z",
     "shell.execute_reply.started": "2023-07-31T06:11:08.238592Z"
    },
    "ExecuteTime": {
     "end_time": "2023-09-29T16:30:58.473664Z",
     "start_time": "2023-09-29T16:30:58.449820Z"
    }
   },
   "outputs": [],
   "source": [
    "TEMPERATURE = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:08.269654Z",
     "iopub.status.busy": "2023-07-31T06:11:08.269017Z",
     "iopub.status.idle": "2023-07-31T06:11:10.109116Z",
     "shell.execute_reply": "2023-07-31T06:11:10.108307Z",
     "shell.execute_reply.started": "2023-07-31T06:11:08.269630Z"
    },
    "ExecuteTime": {
     "end_time": "2023-09-29T16:31:00.376009Z",
     "start_time": "2023-09-29T16:30:59.583720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"I am using OpenAI's GPT-3 model, which is the most advanced version available.\""
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(os.environ['HOME'], '.ssh', 'openai-zillow.json'), 'r') as f:\n",
    "    credentials = json.load(f)\n",
    "os.environ[\"OPENAI_API_KEY\"] = credentials['key']\n",
    "os.environ[\"OPENAI_API_BASE\"] = credentials['url']\n",
    "llm3_5 = ChatOpenAI(model_name='gpt-3.5-turbo-16k', temperature=TEMPERATURE)\n",
    "llm4 = ChatOpenAI(model_name='gpt-4-32k', temperature=TEMPERATURE)\n",
    "\n",
    "conversation = ConversationChain(llm=llm3_5)\n",
    "conversation.predict(input=\"What's your model version?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "('gpt-3.5-turbo-16k', 'gpt-4-32k')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm3_5.model_name, llm4.model_name"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T16:31:01.426047Z",
     "start_time": "2023-09-29T16:31:01.393123Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:10.111826Z",
     "iopub.status.busy": "2023-07-31T06:11:10.111407Z",
     "iopub.status.idle": "2023-07-31T06:12:26.695021Z",
     "shell.execute_reply": "2023-07-31T06:12:26.694244Z",
     "shell.execute_reply.started": "2023-07-31T06:11:10.111799Z"
    },
    "ExecuteTime": {
     "end_time": "2023-09-29T17:25:52.321514Z",
     "start_time": "2023-09-29T17:23:11.960034Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Regular LLM consumed 12285 tokens, exceeded allowance of 10000",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 13\u001B[0m\n\u001B[1;32m      3\u001B[0m executor \u001B[38;5;241m=\u001B[39m Orchestrator(llm\u001B[38;5;241m=\u001B[39mLangChainLLM(llm4, logger\u001B[38;5;241m=\u001B[39mlogger), prompts\u001B[38;5;241m=\u001B[39mprompts, markdown_logger\u001B[38;5;241m=\u001B[39mlogger,\n\u001B[1;32m      4\u001B[0m                         ask_user_before_execute_codes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m      5\u001B[0m                         initial_expansion\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      9\u001B[0m                         \u001B[38;5;66;03m# smarter_llm=LangChainLLM(llm4, logger=logger),\u001B[39;00m\n\u001B[1;32m     10\u001B[0m                         )\n\u001B[1;32m     12\u001B[0m experiment_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexample\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m---> 13\u001B[0m \u001B[43mexecutor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\"\"\u001B[39;49m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;124;43mI want to travel to Moscow. Find me a travel route.\u001B[39;49m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;43m\"\"\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43manalyze_first\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/orchestrator.py:97\u001B[0m, in \u001B[0;36mOrchestrator.start\u001B[0;34m(self, task, analyze_first)\u001B[0m\n\u001B[1;32m     95\u001B[0m     init_analysis_step \u001B[38;5;241m=\u001B[39m AnalysisStep(root_step, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, ROLE_ORCHESTRATOR)\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chain\u001B[38;5;241m.\u001B[39mappend(Invocation(init_analysis_step, _executor\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m))\n\u001B[0;32m---> 97\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_with_backtracking\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/orchestrator.py:113\u001B[0m, in \u001B[0;36mOrchestrator._execute_with_backtracking\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chain) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    112\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 113\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    114\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_frozen_chain \u001B[38;5;241m=\u001B[39m _FrozenList(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chain)\n\u001B[1;32m    115\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/orchestrator.py:174\u001B[0m, in \u001B[0;36mOrchestrator._loop\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    172\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msummarize_final_answer()\n\u001B[1;32m    173\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m--> 174\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_token_usages\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    175\u001B[0m     new_step \u001B[38;5;241m=\u001B[39m new_step\u001B[38;5;241m.\u001B[39meval(new_invocation)\n\u001B[1;32m    176\u001B[0m new_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnext_step()\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/orchestrator.py:188\u001B[0m, in \u001B[0;36mOrchestrator.check_token_usages\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcheck_token_usages\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;241m0\u001B[39m \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_max_tokens \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm\u001B[38;5;241m.\u001B[39mtotal_tokens:\n\u001B[0;32m--> 188\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRegular LLM consumed \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm\u001B[38;5;241m.\u001B[39mtotal_tokens\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m tokens, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    189\u001B[0m                            \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexceeded allowance of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_max_tokens\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    190\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mid\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mid\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msage_llm) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;241m0\u001B[39m \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_max_tokens_for_sage_llm \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msage_llm\u001B[38;5;241m.\u001B[39mtotal_tokens:\n\u001B[1;32m    191\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSmarter LLM consumed \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msage_llm\u001B[38;5;241m.\u001B[39mtotal_tokens\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m tokens, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    192\u001B[0m                            \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexceeded allowance of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_max_tokens_for_sage_llm\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Regular LLM consumed 12285 tokens, exceeded allowance of 10000"
     ]
    }
   ],
   "source": [
    "prompts = PromptDb.load_defaults()\n",
    "logger = MarkdownLogger('logs/taogpt_log.md')\n",
    "executor = Orchestrator(llm=LangChainLLM(llm4, logger=logger), prompts=prompts, markdown_logger=logger,\n",
    "                        ask_user_before_execute_codes=False,\n",
    "                        initial_expansion=1,\n",
    "                        max_tree_branches=2,\n",
    "                        max_tokens=10000,\n",
    "                        check_final=True,\n",
    "                        # smarter_llm=LangChainLLM(llm4, logger=logger),\n",
    "                        )\n",
    "\n",
    "experiment_name = 'example'\n",
    "executor.start(\"\"\"\n",
    "I want to travel to Moscow. Find me a travel route.\n",
    "\"\"\", analyze_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# executor.resume(10000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T16:31:50.634143Z",
     "start_time": "2023-09-29T16:31:50.610485Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:12:26.696369Z",
     "iopub.status.busy": "2023-07-31T06:12:26.696162Z",
     "iopub.status.idle": "2023-07-31T06:12:26.726978Z",
     "shell.execute_reply": "2023-07-31T06:12:26.726366Z",
     "shell.execute_reply.started": "2023-07-31T06:12:26.696352Z"
    },
    "ExecuteTime": {
     "end_time": "2023-09-29T16:42:55.020963Z",
     "start_time": "2023-09-29T16:42:54.954227Z"
    }
   },
   "outputs": [],
   "source": [
    "logger = MarkdownLogger(f'examples/{experiment_name}.final.md')\n",
    "logger.log_conversation(executor.show_conversation_thread(with_extras=True))\n",
    "logger.log(f\"**total tokens**: {executor.llm.total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:12:26.728306Z",
     "iopub.status.busy": "2023-07-31T06:12:26.728050Z",
     "iopub.status.idle": "2023-07-31T06:12:26.762760Z",
     "shell.execute_reply": "2023-07-31T06:12:26.762149Z",
     "shell.execute_reply.started": "2023-07-31T06:12:26.728288Z"
    },
    "ExecuteTime": {
     "end_time": "2023-09-29T16:42:56.238294Z",
     "start_time": "2023-09-29T16:42:56.203225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div style=\"background-color: beige; text-align: center; padding: 5px\">\n<h1>Final path history</h1>\n</div>\n<div style=\"background-color:lightgreen; display: flex; border-bottom: 1px dotted grey\">\n<div style=\"flex: 130px\">\n<p>[0] <strong>user</strong></p>\n</div>\n<div style=\"flex: 100%; border-left: 1px dotted grey; padding-left: 5px\">\n<p>Solve this Game of 24: 7, 6, 2, 1</p>\n</div>\n</div>\n<div style=\"background-color:lightyellow; display: flex; border-bottom: 1px dotted grey\">\n<div style=\"flex: 130px\">\n<p>[1] <strong>Tao</strong></p>\n</div>\n<div style=\"flex: 100%; border-left: 1px dotted grey; padding-left: 5px\">\n<p>The problem statement seems clear and without any fundamental errors, invalid assumptions, or contradictions. The task is to use the four numbers: 7, 6, 2, 1, in any order, using any of the four basic arithmetic operations: addition, subtraction, multiplication, and division, to get the result of 24. Each number must be used exactly once. The problem is solvable if such a combination exists.</p>\n</div>\n</div>\n<div style=\"background-color:lightcyan; display: flex; border-bottom: 1px dotted grey\">\n<div style=\"flex: 130px\">\n<p>[2] <strong>orchestrator</strong></p>\n</div>\n<div style=\"flex: 100%; border-left: 1px dotted grey; padding-left: 5px\">\n<p>Tao, please proceed. You <strong>must follow the response templates strictly</strong> so that your orchestrator\ncan parse your response. Think carefully before responding.</p>\n</div>\n</div>\n<div style=\"background-color:lightyellow; display: flex; border-bottom: 1px dotted grey\">\n<div style=\"flex: 130px\">\n<p>[3] <strong>Tao</strong></p>\n</div>\n<div style=\"flex: 100%; border-left: 1px dotted grey; padding-left: 5px\">\n<p>To solve this problem, we need to find a combination of the four numbers and the four basic arithmetic operations that will result in 24. We can approach this problem by trying different combinations of operations and numbers.</p>\n<ol>\n<li>Try different combinations of the numbers with the basic arithmetic operations.</li>\n<li>Check if the result of the combination is 24.</li>\n<li>If the result is 24, we have found a solution. If not, we need to try a different combination.</li>\n</ol>\n<p>Let's start with the first step. We can try the following combination:</p>\n<p>(7 - 1) * (6 / 2) = 24</p>\n<p>This combination works because the operations are performed in the correct order according to the order of operations (PEMDAS/BODMAS), and each number is used exactly once.</p>\n<p>So, the solution to this Game of 24 problem is:</p>\n<p>(7 - 1) * (6 / 2) = 24.</p>\n</div>\n</div>\n<div style=\"background-color:lightcyan; display: flex; border-bottom: 1px dotted grey\">\n<div style=\"flex: 130px\">\n<p>[4] <strong>orchestrator</strong></p>\n</div>\n<div style=\"flex: 100%; border-left: 1px dotted grey; padding-left: 5px\">\n<p>Tao, please proceed to work on the first step of the above plan. You <strong>must follow the response templates strictly</strong>\nso that your orchestrator can parse your response. Think carefully before responding.</p>\n</div>\n</div>\n<div style=\"background-color:lightyellow; display: flex; border-bottom: 1px dotted grey\">\n<div style=\"flex: 130px\">\n<p>[5] <strong>Tao</strong></p>\n</div>\n<div style=\"flex: 100%; border-left: 1px dotted grey; padding-left: 5px\">\n<p>The solution to the Game of 24 problem with the numbers 7, 6, 2, 1 is:</p>\n<p>(7 - 1) * (6 / 2) = 24</p>\n<p>This solution works because:</p>\n<ul>\n<li>The operations are performed in the correct order according to the order of operations (PEMDAS/BODMAS), which is Parentheses, Exponents, Multiplication and Division (from left to right), Addition and Subtraction (from left to right).</li>\n<li>Each number is used exactly once.</li>\n</ul>\n</div>\n</div>\n<div style=\"background-color:lightyellow; display: flex; border-bottom: 1px dotted grey\">\n<div style=\"flex: 130px\">\n<p>[6] <strong>Tao</strong></p>\n</div>\n<div style=\"flex: 100%; border-left: 1px dotted grey; padding-left: 5px\">\n<p>The solution to the Game of 24 problem with the numbers 7, 6, 2, 1 is:</p>\n<p>(7 - 1) * (6 / 2) = 24</p>\n<p>This solution works because:</p>\n<ul>\n<li>The operations are performed in the correct order according to the order of operations (PEMDAS/BODMAS), which is Parentheses, Exponents, Multiplication and Division (from left to right), Addition and Subtraction (from left to right).</li>\n<li>Each number is used exactly once.</li>\n</ul>\n<p>This solution was found by trying different combinations of the numbers with the basic arithmetic operations and checking if the result of the combination is 24.</p>\n</div>\n</div>\n<p><strong>total tokens</strong>: 4322</p>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(logger._log_path, 'r') as f:\n",
    "    html_output = marko.convert(f.read())\n",
    "    display_html(html_output, raw=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:06.040583Z",
     "iopub.status.busy": "2023-07-31T06:11:06.040283Z",
     "iopub.status.idle": "2023-07-31T06:11:08.236735Z",
     "shell.execute_reply": "2023-07-31T06:11:08.235796Z",
     "shell.execute_reply.started": "2023-07-31T06:11:06.040560Z"
    },
    "ExecuteTime": {
     "end_time": "2023-10-05T23:48:38.050858Z",
     "start_time": "2023-10-05T23:48:36.762613Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "import os\n",
    "\n",
    "from taogpt.orchestrator import *\n",
    "from taogpt.utils import *\n",
    "from taogpt.llm_model import LangChainLLM\n",
    "from taogpt.prompts import PromptDb\n",
    "import taogpt.utils as utils\n",
    "\n",
    "utils.enable_debugging(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T23:48:38.073668Z",
     "start_time": "2023-10-05T23:48:38.052823Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:08.238613Z",
     "iopub.status.busy": "2023-07-31T06:11:08.238227Z",
     "iopub.status.idle": "2023-07-31T06:11:08.268068Z",
     "shell.execute_reply": "2023-07-31T06:11:08.267171Z",
     "shell.execute_reply.started": "2023-07-31T06:11:08.238592Z"
    },
    "ExecuteTime": {
     "end_time": "2023-10-05T23:48:38.089885Z",
     "start_time": "2023-10-05T23:48:38.074029Z"
    }
   },
   "outputs": [],
   "source": [
    "TEMPERATURE = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:08.269654Z",
     "iopub.status.busy": "2023-07-31T06:11:08.269017Z",
     "iopub.status.idle": "2023-07-31T06:11:10.109116Z",
     "shell.execute_reply": "2023-07-31T06:11:10.108307Z",
     "shell.execute_reply.started": "2023-07-31T06:11:08.269630Z"
    },
    "ExecuteTime": {
     "end_time": "2023-10-05T23:48:39.696770Z",
     "start_time": "2023-10-05T23:48:38.716952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"I am using OpenAI's GPT-3 model, which is the third iteration of the Generative Pre-trained Transformer. It was released in June 2020 and has been trained on a wide variety of internet text to generate human-like responses.\""
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(os.environ['HOME'], '.ssh', 'openai-zillow.json'), 'r') as f:\n",
    "    credentials = json.load(f)\n",
    "os.environ[\"OPENAI_API_KEY\"] = credentials['key']\n",
    "os.environ[\"OPENAI_API_BASE\"] = credentials['url']\n",
    "llm3_5 = ChatOpenAI(model_name='gpt-3.5-turbo-16k', temperature=TEMPERATURE)\n",
    "llm4 = ChatOpenAI(model_name='gpt-4-32k', temperature=TEMPERATURE)\n",
    "\n",
    "conversation = ConversationChain(llm=llm3_5)\n",
    "conversation.predict(input=\"What's your model version?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "('gpt-3.5-turbo-16k', 'gpt-4-32k')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm3_5.model_name, llm4.model_name"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T23:48:39.697021Z",
     "start_time": "2023-10-05T23:48:39.678003Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:10.111826Z",
     "iopub.status.busy": "2023-07-31T06:11:10.111407Z",
     "iopub.status.idle": "2023-07-31T06:12:26.695021Z",
     "shell.execute_reply": "2023-07-31T06:12:26.694244Z",
     "shell.execute_reply.started": "2023-07-31T06:11:10.111799Z"
    },
    "ExecuteTime": {
     "end_time": "2023-10-05T23:49:49.597023Z",
     "start_time": "2023-10-05T23:48:48.586746Z"
    }
   },
   "outputs": [
    {
     "ename": "Pause",
     "evalue": "Pause after initial solving expansion",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mPause\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 22\u001B[0m\n\u001B[1;32m     13\u001B[0m executor \u001B[38;5;241m=\u001B[39m Orchestrator(\n\u001B[1;32m     14\u001B[0m     config\u001B[38;5;241m=\u001B[39mconfig,\n\u001B[1;32m     15\u001B[0m     llm\u001B[38;5;241m=\u001B[39mLangChainLLM(llm4, logger\u001B[38;5;241m=\u001B[39mlogger),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;66;03m# sage_llm=LangChainLLM(llm4, logger=logger),\u001B[39;00m\n\u001B[1;32m     19\u001B[0m )\n\u001B[1;32m     21\u001B[0m experiment_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexample\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m---> 22\u001B[0m \u001B[43mexecutor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\"\"\u001B[39;49m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;124;43mSolve this 4x4 Sudoku represented by the 2-D Python array where 0 is the empty cell:\u001B[39;49m\n\u001B[1;32m     24\u001B[0m \n\u001B[1;32m     25\u001B[0m \u001B[38;5;124;43m```python\u001B[39;49m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;124;43m[\u001B[39;49m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;124;43m    [0, 3, 0, 1],\u001B[39;49m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;124;43m    [1, 0, 0, 3],\u001B[39;49m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;124;43m    [2, 0, 3, 4],\u001B[39;49m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;124;43m    [3, 4, 0, 2],\u001B[39;49m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;124;43m]\u001B[39;49m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;124;43m```\u001B[39;49m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;124;43m\"\"\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43manalyze_first\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/orchestrator.py:84\u001B[0m, in \u001B[0;36mOrchestrator.start\u001B[0;34m(self, task, analyze_first)\u001B[0m\n\u001B[1;32m     82\u001B[0m     init_analysis_step \u001B[38;5;241m=\u001B[39m AnalysisStep(root_step, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, ROLE_ORCHESTRATOR)\n\u001B[1;32m     83\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chain\u001B[38;5;241m.\u001B[39mappend(Invocation(init_analysis_step, _executor\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m))\n\u001B[0;32m---> 84\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_with_backtracking\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/orchestrator.py:104\u001B[0m, in \u001B[0;36mOrchestrator._execute_with_backtracking\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chain) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    103\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 104\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    105\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_frozen_chain \u001B[38;5;241m=\u001B[39m _FrozenList(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chain)\n\u001B[1;32m    106\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/orchestrator.py:157\u001B[0m, in \u001B[0;36mOrchestrator._loop\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    155\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    156\u001B[0m     invocation \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chain[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m--> 157\u001B[0m     new_step \u001B[38;5;241m=\u001B[39m \u001B[43minvocation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval\u001B[49m\u001B[43m(\u001B[49m\u001B[43minvocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    158\u001B[0m     invocation\u001B[38;5;241m.\u001B[39mexecution_count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    159\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m new_step \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/program.py:67\u001B[0m, in \u001B[0;36mStep.eval\u001B[0;34m(self, my_invocation)\u001B[0m\n\u001B[1;32m     65\u001B[0m sig \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msid\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m@\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mid\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m@\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mid\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mid\u001B[39m(my_invocation\u001B[38;5;241m.\u001B[39mstep)\n\u001B[0;32m---> 67\u001B[0m returned \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval_only\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmy_invocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m returned\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/program.py:554\u001B[0m, in \u001B[0;36mExpandableStep.eval_only\u001B[0;34m(self, my_invocation)\u001B[0m\n\u001B[1;32m    552\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrank_choices(my_invocation, n_existing_choices\u001B[38;5;241m=\u001B[39mold_length)\n\u001B[1;32m    553\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfirst_problem_solving_step \u001B[38;5;129;01mand\u001B[39;00m my_invocation\u001B[38;5;241m.\u001B[39mexecutor\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mpause_after_initial_solving_expansion:\n\u001B[0;32m--> 554\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Pause(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPause after initial solving expansion\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    555\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchoices \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchoices) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    556\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Backtrack(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNo viable options.\u001B[39m\u001B[38;5;124m'\u001B[39m, blame\u001B[38;5;241m=\u001B[39mmy_invocation)\n",
      "\u001B[0;31mPause\u001B[0m: Pause after initial solving expansion"
     ]
    }
   ],
   "source": [
    "prompts = PromptDb.load_defaults()\n",
    "logger = MarkdownLogger('logs/taogpt_log.md')\n",
    "config = Config(\n",
    "    ask_user_before_execute_codes=False,\n",
    "    ask_user_questions_in_one_prompt=True,\n",
    "    pause_after_initial_solving_expansion=True,\n",
    "    first_expansion=1,\n",
    "    initial_expansion=4,\n",
    "    max_tree_branches=6,\n",
    "    max_tokens=5000,\n",
    "    check_final=True\n",
    ")\n",
    "executor = Orchestrator(\n",
    "    config=config,\n",
    "    llm=LangChainLLM(llm4, logger=logger),\n",
    "    prompts=prompts,\n",
    "    markdown_logger=logger,\n",
    "    # sage_llm=LangChainLLM(llm4, logger=logger),\n",
    ")\n",
    "\n",
    "experiment_name = 'example'\n",
    "executor.start(\"\"\"\n",
    "Solve this 4x4 Sudoku represented by the 2-D Python array where 0 is the empty cell:\n",
    "\n",
    "```python\n",
    "[\n",
    "    [0, 3, 0, 1],\n",
    "    [1, 0, 0, 3],\n",
    "    [2, 0, 3, 4],\n",
    "    [3, 4, 0, 2],\n",
    "]\n",
    "```\n",
    "\n",
    "Solve it in your head, do not write codes.\n",
    "\"\"\", analyze_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extend token allowance by 10000 to 15000\n",
      "extend token allowance for smarter LLM by 1000 to 6000\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Regular LLM consumed 17042 tokens, exceeded allowance of 15000",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mexecutor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresume\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m10000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madditional_tokens_for_smarter_llm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43munblock_initial_expansion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/orchestrator.py:97\u001B[0m, in \u001B[0;36mOrchestrator.resume\u001B[0;34m(self, additional_tokens, unblock_initial_expansion, additional_tokens_for_smarter_llm)\u001B[0m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m unblock_initial_expansion:\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mpause_after_initial_solving_expansion \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m---> 97\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_with_backtracking\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/orchestrator.py:103\u001B[0m, in \u001B[0;36mOrchestrator._execute_with_backtracking\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chain) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    102\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 103\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    104\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_frozen_chain \u001B[38;5;241m=\u001B[39m _FrozenList(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chain)\n\u001B[1;32m    105\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/orchestrator.py:164\u001B[0m, in \u001B[0;36mOrchestrator._loop\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    162\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msummarize_final_answer()\n\u001B[1;32m    163\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m--> 164\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_token_usages\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    165\u001B[0m     new_step \u001B[38;5;241m=\u001B[39m new_step\u001B[38;5;241m.\u001B[39meval(new_invocation)\n\u001B[1;32m    166\u001B[0m new_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnext_step()\n",
      "File \u001B[0;32m~/ml/taogpt/src/taogpt/orchestrator.py:178\u001B[0m, in \u001B[0;36mOrchestrator.check_token_usages\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcheck_token_usages\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;241m0\u001B[39m \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mmax_tokens \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm\u001B[38;5;241m.\u001B[39mtotal_tokens:\n\u001B[0;32m--> 178\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRegular LLM consumed \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm\u001B[38;5;241m.\u001B[39mtotal_tokens\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m tokens, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    179\u001B[0m                            \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexceeded allowance of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mmax_tokens\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    180\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mid\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mid\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msage_llm) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;241m0\u001B[39m \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mmax_tokens_for_sage_llm \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msage_llm\u001B[38;5;241m.\u001B[39mtotal_tokens:\n\u001B[1;32m    181\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSmarter LLM consumed \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msage_llm\u001B[38;5;241m.\u001B[39mtotal_tokens\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m tokens, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    182\u001B[0m                            \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexceeded allowance of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mmax_tokens_for_sage_llm\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Regular LLM consumed 17042 tokens, exceeded allowance of 15000"
     ]
    }
   ],
   "source": [
    "executor.resume(10000, additional_tokens_for_smarter_llm=1000, unblock_initial_expansion=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T23:15:21.164289Z",
     "start_time": "2023-10-05T23:15:11.714922Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:12:26.696369Z",
     "iopub.status.busy": "2023-07-31T06:12:26.696162Z",
     "iopub.status.idle": "2023-07-31T06:12:26.726978Z",
     "shell.execute_reply": "2023-07-31T06:12:26.726366Z",
     "shell.execute_reply.started": "2023-07-31T06:12:26.696352Z"
    },
    "ExecuteTime": {
     "end_time": "2023-10-05T22:13:40.111152Z",
     "start_time": "2023-10-05T22:13:40.081816Z"
    }
   },
   "outputs": [],
   "source": [
    "logger = MarkdownLogger(f'examples/{experiment_name}.final.md')\n",
    "logger.log_conversation(executor.show_conversation_thread(with_extras=True))\n",
    "logger.log(f\"**total tokens**: {executor.llm.total_tokens}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

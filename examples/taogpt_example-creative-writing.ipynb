{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install langchain openai marko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:05.457691Z",
     "iopub.status.busy": "2023-07-31T06:11:05.457328Z",
     "iopub.status.idle": "2023-07-31T06:11:05.487385Z",
     "shell.execute_reply": "2023-07-31T06:11:05.486700Z",
     "shell.execute_reply.started": "2023-07-31T06:11:05.457663Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:06.040583Z",
     "iopub.status.busy": "2023-07-31T06:11:06.040283Z",
     "iopub.status.idle": "2023-07-31T06:11:08.236735Z",
     "shell.execute_reply": "2023-07-31T06:11:08.235796Z",
     "shell.execute_reply.started": "2023-07-31T06:11:06.040560Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "import os\n",
    "from IPython.display import display_html\n",
    "import marko\n",
    "\n",
    "from taogpt.orchestrator import *\n",
    "from taogpt.utils import *\n",
    "from taogpt.tao_model import LangChainLLM, PromptSet, get_last_conversation\n",
    "import taogpt.utils as utils\n",
    "\n",
    "utils.enable_debugging(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:08.238613Z",
     "iopub.status.busy": "2023-07-31T06:11:08.238227Z",
     "iopub.status.idle": "2023-07-31T06:11:08.268068Z",
     "shell.execute_reply": "2023-07-31T06:11:08.267171Z",
     "shell.execute_reply.started": "2023-07-31T06:11:08.238592Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "GPT_MODEL = 'gpt-4-32k'\n",
    "TEMPERATURE = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:08.269654Z",
     "iopub.status.busy": "2023-07-31T06:11:08.269017Z",
     "iopub.status.idle": "2023-07-31T06:11:10.109116Z",
     "shell.execute_reply": "2023-07-31T06:11:10.108307Z",
     "shell.execute_reply.started": "2023-07-31T06:11:08.269630Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"I'm sorry, as an AI, I don't have the ability to provide a specific model version. My programming is continuously updated and improved upon to provide the best assistance possible.\""
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(os.environ['HOME'], '.ssh', 'openai-zillow.key'), 'r') as f:\n",
    "    key = ''.join(f.readlines()).strip()\n",
    "os.environ[\"OPENAI_API_KEY\"] = key\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://zgai-llm-api.int.stage-k8s.zg-aip.net/openai/v1\"\n",
    "llm = ChatOpenAI(model_name=GPT_MODEL, temperature=TEMPERATURE)\n",
    "\n",
    "conversation = ConversationChain(llm=llm)\n",
    "conversation.predict(input=\"What's your model version?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:11:10.111826Z",
     "iopub.status.busy": "2023-07-31T06:11:10.111407Z",
     "iopub.status.idle": "2023-07-31T06:12:26.695021Z",
     "shell.execute_reply": "2023-07-31T06:12:26.694244Z",
     "shell.execute_reply.started": "2023-07-31T06:11:10.111799Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "prompts = PromptSet.load_defaults()\n",
    "logger = MarkdownLogger('logs/taogpt_log.md')\n",
    "executor = Orchestrator(llm=LangChainLLM(llm, logger=logger), prompts=prompts, markdown_logger=logger)\n",
    "executor.start(\"\"\"Write a coherent passage of 4 short paragraphs. The end of each paragraph must be:\n",
    "\n",
    "1. He found rain fascinating yet unpleasant.\n",
    "2. Abstraction is often one floor above you.\n",
    "3. Courage and stupidity were all he had.\n",
    "4. He had a wall full of masks so she could wear a different face every day.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:12:26.696369Z",
     "iopub.status.busy": "2023-07-31T06:12:26.696162Z",
     "iopub.status.idle": "2023-07-31T06:12:26.726978Z",
     "shell.execute_reply": "2023-07-31T06:12:26.726366Z",
     "shell.execute_reply.started": "2023-07-31T06:12:26.696352Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "logger = MarkdownLogger('/tmp/taogpt_final.md')\n",
    "logger.log_conversation(executor.show_conversation_thread(with_extras=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-31T06:12:26.728306Z",
     "iopub.status.busy": "2023-07-31T06:12:26.728050Z",
     "iopub.status.idle": "2023-07-31T06:12:26.762760Z",
     "shell.execute_reply": "2023-07-31T06:12:26.762149Z",
     "shell.execute_reply.started": "2023-07-31T06:12:26.728288Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with open(logger._log_path, 'r') as f:\n",
    "    html_output = marko.convert(f.read())\n",
    "    with open('/tmp/taogpt_final.html', 'w') as out:\n",
    "        out.write(html_output)\n",
    "    display_html(html_output, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generated by GPT with default system prompt (8/16/2023)\n",
    "\n",
    "(Obvious mistakes highlighted in **bold**.)\n",
    "\n",
    "Ever since childhood, Jacob had a unique interest in the weather. He loved how a day could shift its mood as certain\n",
    "atmospheric conditions changed. And out of all, he was most intrigued by rain. It stirred emotions within him. The\n",
    "rhythmic patter of raindrops against window panes, the earthy smell that arose from parched soil, the peaceful gloom\n",
    "brought by the heavy clouds; he found these aspects mysterious and soothing. However, the chilly winds that often\n",
    "accompanied and the obstacles it posed in daily commute were bothersome. **Thus,** he found rain fascinating yet unpleasant.\n",
    "\n",
    "Jacob was a philosopher at heart. He loved pondering over life, reality, and the universe. Amid his constant\n",
    "introspection and musings, he realized one significant truth about understanding abstract concepts. It seemed, the\n",
    "more he tried to understand, visualize or define something abstract, the more it eluded his grasp. To him, it felt\n",
    "like chasing a mirage, only to find the image constantly moving further away. **This led him to believe that**\n",
    "abstraction is often one floor above you.\n",
    "\n",
    "Despite his philosophical bent, life was not always kind to Jacob. He faced his fair share of trails and tribulations. Financial struggles, family disputes, failed relationships, bouts of loneliness; he had seen it all. Yet, in the face of adversity, he never bowed down. With his spirit unbroken and unyielding, he tackled every challenge that stood in his path. Were all his decisions wise? Definitely not. But he was not afraid to make mistakes. Courage and stupidity were all he had.\n",
    "\n",
    "Jacob's philosophical nature was complemented by an artistic streak, evidenced by Evangeline, his partner. Evangline\n",
    "lived with multiple identities in her mind, and with each identity came a myriad of unique expressions. To celebrate\n",
    "this, Jacob filled their shared home's wall with a collection of masks, each one representing a different mood or\n",
    "persona. This was not just an artistic choice, it was also symbolic of the myriad faces that Evangeline could choose\n",
    "from, allowing her to freely explore her multitude of identities. **Thus,** he had a wall full of masks so she could wear a different face every day."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
